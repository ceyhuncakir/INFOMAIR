{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b91c46-b777-4126-8a37-168631a37cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e04d6-68c6-4474-b523-1b0b584a05af",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Before we can analyse the data, we first need to load in the data we got provided from the UU. This data originates from the following source (https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/). Since this data is an .dat formatted file we can traditionally use the pd.read_csv() function in order to load this data in, however we can use pd.read_table() function for this. This results us the following dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a02c1-0c8c-451d-9e1f-9373e9ef57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"../data/dialog_acts.dat\", header=None, names=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c2447-2e17-4cd1-948f-44564cbdc753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1d16b-d954-4ab7-b750-50cc00d12ec3",
   "metadata": {},
   "source": [
    "# Correctly setting up axis\n",
    "Since there is no headers marked inside the .dat file, indicating which of the words or combination of words are representing the act or utterance. To distinguis this between eachother we can split on the white spaces inbetween the words and choose the appriopate selection to split appart the act and utterance from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f5809-c150-45e1-a05d-adaf9a54a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(row):\n",
    "    \n",
    "    seperate_words = row.split(\" \")\n",
    "\n",
    "    act, utterance = seperate_words[0], ' '.join(seperate_words[1:])\n",
    "    \n",
    "    return pd.Series([act, utterance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b322f-53bb-4cd7-aec2-b50797333767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['act', 'utterance']] = df.apply(lambda row: get_features(row=row['data']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7933d78-eabc-4598-b9da-1741c0dc1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb586c-4996-4aa8-81f5-c3cdd18d3a52",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "Before we can look at the data, we would also like to see whether we have a need to clean the data before usage. We will check the following steps whether it can be correctly used, Occurences of NaN value, Settings the words to lowercase, and checking for any leading whitespaces that can occur within the utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5c42c-e174-4188-bd59-efcfba4b2f1c",
   "metadata": {},
   "source": [
    "## Check NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98841c-d964-46ad-b1f9-ea888364fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc2a6d-8d06-4c6a-b8e4-2a2724c7c416",
   "metadata": {},
   "source": [
    "## Set lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf7006-4566-4ef9-836f-a82e437f2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['act'] = df['act'].str.lower()\n",
    "df['utterance'] = df['utterance'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03824bdf-1172-4b4f-b7f1-48cad5703837",
   "metadata": {},
   "source": [
    "## Check leading spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76930e69-ce9f-4066-93a9-47c22c6500d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['utterance'] = df['utterance'].str.lstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c3fd6-2932-458b-a89f-b83d82591bdf",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25233eb9-33c3-4917-880e-d5353ba6db1b",
   "metadata": {},
   "source": [
    "## Act distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766a2ac-26fb-4c46-9d3b-4a990bca3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    df,\n",
    "    x=\"act\",\n",
    "    multiple=\"stack\",\n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    log_scale=True,\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b5cc6-79c9-4f4d-92ae-956899ae2ec6",
   "metadata": {},
   "source": [
    "## Token count distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde3306-d5be-490f-b73a-22d11fb442b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_char_count_per_act = df.groupby(\"act\")[\"utterance\"].apply(lambda x: x.str.len().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43745d-a965-4857-bcac-ef96da00f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mccpa = mean_char_count_per_act.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af6ef2-ba03-453e-8347-d72338231e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='act', y='utterance', data=mccpa)\n",
    "plt.xticks(rotation=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cb482-8b9e-4097-83f6-53a6f8dafc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
